{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f55e897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b337f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76fd2038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd4cd311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_digits()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "389a4cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5AAAAEiCAYAAACP0T1zAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAPu0lEQVR4nO3Z/6+W9X3H8SMcsICUoUQckuO3IzCYtliH0hURCSn7kgB2rVZdp8HR4tbUYputzEWWbGjS1C9p9dSuRVu1wlyGZF1FiXUnOFG7lgaLwoniIBE9iCJjKAXOYf/BfI/X8VyenMfjZ565Puh13/f14jrh2LFjx1oAAADgfQxp+gAAAAAMDAYkAAAAJQYkAAAAJQYkAAAAJQYkAAAAJQYkAAAAJQYkAAAAJQYkAAAAJQYkAAAAJa3VPzhvyGc/yHO8r71LZkb9129aHfV/+4sFUT9p2etRf/SN7qhPbeh9pNHrN6npez814dnRUX/uyD1R/+jtl0X92Ps3RX1qMN/7LS0D//5/d9FFUf+DO2+P+ltfnx/1uy8+EPWpwXz/N33vv3pr9tzT9WcdUb/6wNiof2D2jKj33NOcpu/91NDxp0b9ew+OiPrh83ZGfdMq9743kAAAAJQYkAAAAJQYkAAAAJQYkAAAAJQYkAAAAJQYkAAAAJQYkAAAAJQYkAAAAJQYkAAAAJQYkAAAAJQYkAAAAJQYkAAAAJQYkAAAAJQYkAAAAJS0Nn2Aqq/ftDrqrxy9L+rv/K3/ifp/++XjUf+JFUujftz3NkU9A9d/HTg56u9r2xj1/3jJrKgfe3+UM8D1zp4e9Rvvvjfqu45EecuCUzZHfUdLe3YAGtPVMSPqb70se+753btuiPpff+WeqP/2rDOj/qRHuqOewevVpdn35uFf90Z9e8vOqB8IvIEEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgpLW/LnT0sk9E/ZWjfxX1fzD/yqgfs2Vb1H/u6blR//b0nqgfF9U0qXf29Ki/d9J3whOMiuqPvjA8vD6D2Y6FJ0b9yr2To/4HT86J+leu+G7Ud0Q1TZrS8d9R/8DfzYj6mzsfjvrVB8ZG/UmPPBf1DF5Dx58a9X96+ZNRv+a+7Jl96LTsdyfVs3X7B34NbyABAAAoMSABAAAoMSABAAAoMSABAAAoMSABAAAoMSABAAAoMSABAAAoMSABAAAoMSABAAAoMSABAAAoMSABAAAoMSABAAAoMSABAAAoMSABAAAoMSABAAAoae2vCx06JbvUzXvOi/reLduiPvXzF85p9Po0Z9eKT0b9uuu+GfWTho2K+tTpT7wV9T19dA4Gpsm37Yj6NbvmRv1jN2afvzlbr4r64S07o57mxM8d50+J8itH74v6z+3IPjutp2XPfUff6I56Bq5Xl7ZH/Z1j1kZ95x0jov6lVRdG/ZD92Wen/atRXuINJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACWt/XWhQ2OzrfrQpplRP6nl+ahPtY45HPVH9w/vo5PQ39pWPBP1N3Ysivqfbn4i6lNHxo2Mev/KNbANHX9q1G//67OjfvHcJ6M+NeKa96K+p4/OwcDTu2Vb1P/RBZ+O+unrd0d9y/os3zx/QtQffaM7OwDHbd+12TP7S0vuifppm5ZE/cSWrVH/6vzvR/3HvnlD1PcHz2YAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUtPbXhT6yrzfqf++8V6J+f1S3tLSeNj7qr5j6i6j/p8c+FfXQlD0XjIj60zr76CA04qVb26L+1fnf7aOTHJ8Zy78W9WO7N/XRSeD/5+gb3VG/ef6EqH9r1eio777l5KiftDT7+3P8TtyfPfN3HTkY9VtnPhT1K7dMjvrU6T9+Oep7+ugc/xdvIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAAChp7a8LfXT7/qi/ZeJPov4LS5ZF/bCFb0Z96qxvbGr0+gDHo/2HPVG/8sLJUb983Paof35lR9TPuXpB1B98aELUj73fb8dA1dUxI+on/OyEqD80NnvH8KOpt0f9wneWRj3NGbn2uaj/8trfj/re2dOj/u4ffSfqp21aEvUTu7dGfX/wBhIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAICS1v66UO+WbVF/RcdNUX/zTQ9H/Z2vzI36n398aNQzePV074n6OVsXRP1T09ZF/dFP7Y/6ljuynGYN6dwc9Z3nj4j6p2ZfF/VHb347u374+Tnrkuujfuz9UU6Dhr2TPTd8+e9X99FJjs/CZ5ZG/dlX/apvDsKgM2zvu1E/adioqD/5wZOifiDwBhIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAICSE44dO3as6UMAAADw4ecNJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACWt1T84b8hnP8hzvK8Jz46O+udfa4v6iZ/ZGvUD3YbeR5o+QmOavvdT6Wfn3JF7or7z/BFR37TBfO+3tDR//+9a8cmoPzymN+oXz30q6peP2x71XUcORv2NMxZF/frX7476gazpe79r1YVRf8es1VF/00+uifrJt+2I+p7u7LcnNZi/+5u+9w9vOCPqzxz9dtTvvvhA1A90lXvfG0gAAABKDEgAAABKDEgAAABKDEgAAABKDEgAAABKDEgAAABKDEgAAABKDEgAAABKDEgAAABKDEgAAABKDEgAAABKDEgAAABKDEgAAABKDEgAAABKWps+QNWCUzZH/X1tG7MD7M7yRw+eFPUd57ZnB2DA2nftzKh/vK0j6s9Z86Wob295NuohMXx/9u+kj91yadRvuGFK1J85+u2o7+neE/U059Kp2xu9/rf++MGoXzdzetTvvjjKadDQaZOj/qlpa/roJMcpfOZfuTf7+3eePyI7QD/wBhIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAIASAxIAAICS1qYPUPXie6dH/cJR26O+68jBqP+bLVdH/Rnj34z6nu49UU9zFi77WaPXP/vR3zR6fQa3thXPNHr9l++4OOoXj98W9U/POyPqW1oOhD1N+fcXJ0f982Paon7iZ7ZG/bd3ro/6xYuWRf3Itc9FPcfvyLiRjV7/ul2zov7517LPzj+cvy7qO1vao74/eAMJAABAiQEJAABAiQEJAABAiQEJAABAiQEJAABAiQEJAABAiQEJAABAiQEJAABAiQEJAABAiQEJAABAiQEJAABAiQEJAABAiQEJAABAiQEJAABAiQEJAABASWvTB6ja0D0l6peP2x71k4aNivreF8ZEfU/31qhn4Jo64rWoX7l3ctQP6dwc9Qxu7y66KOp3X3JCH53k+Dx2+bcavf6aq+ZG/Wl37Omjk9Df2n/YE/UbHn4o6q97dlbUv3h4fNSP7non6rP/eiSGbcueW1LdC0ZE/Yx1u6J+6vDuqG9paQ/7D543kAAAAJQYkAAAAJQYkAAAAJQYkAAAAJQYkAAAAJQYkAAAAJQYkAAAAJQYkAAAAJQYkAAAAJQYkAAAAJQYkAAAAJQYkAAAAJQYkAAAAJQYkAAAAJQYkAAAAJS0Nn2AquHzdkb9rEVfjPq9Hxsa9S8tuSfqf6flhqhvW/FM1NOcqcO7o37dW9OjfteK86L+rEfeivqerdujnmaN7non6ttuOBT19076cdSnFt+4LOpPW+u7e7A6dPLwRq9/X9vGqP/DeVdEve/+gaune0/Ur9w7Oep/uvmJqD9r/fVR/43fXh/1Q6dlf//++Ox4AwkAAECJAQkAAECJAQkAAECJAQkAAECJAQkAAECJAQkAAECJAQkAAECJAQkAAECJAQkAAECJAQkAAECJAQkAAECJAQkAAECJAQkAAECJAQkAAECJAQkAAEBJa9MH6C8j1z4X9eNaLuqjkxyfQ22HG70+zfnn/RdE/X1tG6N+5eV7on75ku1RP+/z10X9kM7NUU+mZ2v2/3/4vOz6k3aPivoZy5dG/di1m6Kegat39vSo33j3vVF/zpovRf1H2g5E/dUP/2fUP/35j0d9+t1DczrPHxH1T83OnhsmdWb37qdXfSXqz7zzzahPfzcrvIEEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgxIAEAACgpLXpA1Ttu3Zm1J+4vzfq2//qxahPTfzXoY1en+Y88C9zo375ku1Rv6F7StT/yZhfRv2OhSdGfXtnlNOwrlUXZv2R/4j6cY+9EvU9Uc1ANmzba1HfdeRg1E++bUfUH5lyetQvfzj77Tnn+jlR3/7VKGcAG9K5OerT353H594V9YtvXBb1w1t2Rn2FN5AAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUGJAAAACUtDZ9gKo3LzkS9a/O/34fneT4TNt0ddRPXPtcH52Egeasjpezvu36qH987l1R/8Wuq6L+7Ed/E/UMbH9+4caov+aWr0X92O5NUc/g1dO9J+rT786nNq+L+q4jB6N+ztbs/JNv2xH1PVFNk7pWXRj1l07dHvWzR2a/O3/xhb+M+pGdH/5nfm8gAQAAKDEgAQAAKDEgAQAAKDEgAQAAKDEgAQAAKDEgAQAAKDEgAQAAKDEgAQAAKDEgAQAAKDEgAQAAKDEgAQAAKDEgAQAAKDEgAQAAKDEgAQAAKDEgAQAAKDnh2LFjx5o+BAAAAB9+3kACAABQYkACAABQYkACAABQYkACAABQYkACAABQYkACAABQYkACAABQYkACAABQYkACAABQ8r99vmNJD1BYTwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1000x300 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_,axes = plt.subplots(nrows=2,ncols=5,figsize = (10,3))\n",
    "for ax, image, label in zip(axes.ravel(),data.images,data.target):\n",
    "    ax.axis('off')\n",
    "    ax.imshow(image)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0a68c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 8, 8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c719536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed7329eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e2c7587",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(data.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d838378",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.images.reshape((length,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c684b990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46662018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "76d5dabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c60c8e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4afa556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "96ad870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df/df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2cbbb352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed2d4071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "02cabaff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.    , 0.    , 0.3125, 0.8125, 0.5625, 0.0625, 0.    , 0.    ,\n",
       "       0.    , 0.    , 0.8125, 0.9375, 0.625 , 0.9375, 0.3125, 0.    ,\n",
       "       0.    , 0.1875, 0.9375, 0.125 , 0.    , 0.6875, 0.5   , 0.    ,\n",
       "       0.    , 0.25  , 0.75  , 0.    , 0.    , 0.5   , 0.5   , 0.    ,\n",
       "       0.    , 0.3125, 0.5   , 0.    , 0.    , 0.5625, 0.5   , 0.    ,\n",
       "       0.    , 0.25  , 0.6875, 0.    , 0.0625, 0.75  , 0.4375, 0.    ,\n",
       "       0.    , 0.125 , 0.875 , 0.3125, 0.625 , 0.75  , 0.    , 0.    ,\n",
       "       0.    , 0.    , 0.375 , 0.8125, 0.625 , 0.    , 0.    , 0.    ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9ac01532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "50c8cd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(df,data.target,test_size=.4,random_state=2549)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8529f058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "70b4d8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "027cd231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bd337dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4bce9433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e7d10489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 70,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1,  0, 65,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 79,  0,  0,  0,  2,  0,  1],\n",
       "       [ 0,  0,  0,  0, 67,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 72,  1,  0,  1,  0],\n",
       "       [ 1,  2,  0,  0,  0,  1, 79,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 77,  0,  0],\n",
       "       [ 0,  1,  0,  1,  0,  0,  0,  0, 65,  1],\n",
       "       [ 0,  1,  0,  0,  0,  1,  0,  0,  0, 60]], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "28710f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        70\n",
      "           1       0.95      1.00      0.97        70\n",
      "           2       1.00      0.98      0.99        66\n",
      "           3       0.99      0.96      0.98        82\n",
      "           4       1.00      1.00      1.00        67\n",
      "           5       0.97      0.97      0.97        74\n",
      "           6       0.99      0.95      0.97        83\n",
      "           7       0.97      1.00      0.99        77\n",
      "           8       0.98      0.96      0.97        68\n",
      "           9       0.97      0.97      0.97        62\n",
      "\n",
      "    accuracy                           0.98       719\n",
      "   macro avg       0.98      0.98      0.98       719\n",
      "weighted avg       0.98      0.98      0.98       719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64c8edb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
